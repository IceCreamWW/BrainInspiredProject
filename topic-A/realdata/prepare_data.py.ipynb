{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Index', 'From', 'To', 'Subject', 'Cc', 'Content', 'Action'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_dataset = \"./data.json\"\n",
    "with open(path_to_dataset) as fp:\n",
    "    dataset = json.load(fp)\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Here is our forecast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Randy, Can you send me a schedule of the salar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Action\n",
       "0                              Here is our forecast        0\n",
       "1  Traveling to have a business meeting takes the...       1\n",
       "2                     test successful.  way to go!!!       1\n",
       "3  Randy, Can you send me a schedule of the salar...       0\n",
       "4                Let's shoot for Tuesday at 11:45.         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(dataset)\n",
    "df = df[['Content','Action']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GloVe Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_model(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "path_to_glove = \"./glove.6B.50d.txt\"\n",
    "glove = load_glove_model(path_to_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocess\n",
    "1. Tokenization\n",
    "2. Remove Stopwords\n",
    "3. Replace number with NUM. Replace OOV with UNK\n",
    "4. Selected 10000 most frequent tokens\n",
    "5. Pad with NIL and truncate to 300\n",
    "6. Split dataset to train, dev by 7:3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuations\n",
    "df['Content'] = df['Content'].str.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['raw_tokens'] = df['Content'].apply(lambda sentence: nltk.word_tokenize(sentence))\n",
    "df['raw_tokens'] = df['Content'].apply(lambda sentence: sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['raw_tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['tokens'].apply(lambda tokens: [token for token in tokens if token.lower() not in ENGLISH_STOP_WORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                               [forecast]\n",
       "1        [Traveling, business, meeting, takes, fun, tri...\n",
       "2                                  [test, successful, way]\n",
       "3        [Randy, send, schedule, salary, level, schedul...\n",
       "4                             [Lets, shoot, Tuesday, 1145]\n",
       "                               ...                        \n",
       "99995    [Forwarded, Daren, J, FarmerHOUECT, 122799, 08...\n",
       "99996    [occurred, point, prior, months, allocated, vo...\n",
       "99997    [AimeePGEs, numbers, correct, Aimee, Lannou, 1...\n",
       "99998    [Forwarded, Daren, J, FarmerHOUECT, 122299, 06...\n",
       "99999    [Vintage, 93730Julie, Meyers122099, 0227, PMTo...\n",
       "Name: tokens, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace number with NUM; Replace OOV with UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_token(token):\n",
    "    if token.isdigit():\n",
    "        return '<NUM>'\n",
    "    elif token.lower() not in glove:\n",
    "        return '<UNK>'\n",
    "    else:\n",
    "        return token\n",
    "\n",
    "df['tokens'] = df['tokens'].apply(lambda tokens: [replace_token(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                               [forecast]\n",
       "1        [Traveling, business, meeting, takes, fun, tri...\n",
       "2                                  [test, successful, way]\n",
       "3        [Randy, send, schedule, salary, level, schedul...\n",
       "4                            [Lets, shoot, Tuesday, <NUM>]\n",
       "                               ...                        \n",
       "99995    [Forwarded, Daren, J, <UNK>, <NUM>, <NUM>, SUS...\n",
       "99996    [occurred, point, prior, months, allocated, <U...\n",
       "99997    [<UNK>, numbers, correct, Aimee, <UNK>, <NUM>,...\n",
       "99998    [Forwarded, Daren, J, <UNK>, <NUM>, <NUM>, Enr...\n",
       "99999    [Vintage, <UNK>, <UNK>, <NUM>, <UNK>, Daren, J...\n",
       "Name: tokens, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select 10000 most frequent tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2freq = {}\n",
    "for tokens in df['tokens']:\n",
    "    for token in tokens:\n",
    "        if token.lower() in token2freq:\n",
    "            token2freq[token.lower()] += 1\n",
    "        else:\n",
    "            token2freq[token.lower()] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_tokens = set(sorted(token2freq.keys(), key=lambda token: -token2freq[token])[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['tokens'].apply(lambda tokens: [token for token in tokens if token.lower() in selected_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                               [forecast]\n",
       "1        [Traveling, business, meeting, takes, fun, tri...\n",
       "2                                  [test, successful, way]\n",
       "3        [Randy, send, schedule, salary, level, schedul...\n",
       "4                            [Lets, shoot, Tuesday, <NUM>]\n",
       "                               ...                        \n",
       "99995    [Forwarded, Daren, J, <UNK>, <NUM>, <NUM>, SUS...\n",
       "99996    [occurred, point, prior, months, allocated, <U...\n",
       "99997    [<UNK>, numbers, correct, Aimee, <UNK>, <NUM>,...\n",
       "99998    [Forwarded, Daren, J, <UNK>, <NUM>, <NUM>, Enr...\n",
       "99999    [<UNK>, <UNK>, <NUM>, <UNK>, Daren, J, <UNK>, ...\n",
       "Name: tokens, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad with NIL; Truncate to 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_truncate_tokens(tokens):\n",
    "    if len(tokens) >= 300:\n",
    "        return tokens[:300]\n",
    "    else:\n",
    "        return tokens + ['<NIL>'] * (300 - len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lengths'] = df['tokens'].apply(lambda tokens: len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['tokens'].apply(lambda tokens: pad_or_truncate_tokens(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = reduce(lambda x,y: x | set(y), df['tokens'], set([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2id = {token: idx for idx, token in enumerate(all_tokens)}\n",
    "id2token = all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_ids'] = df['tokens'].apply(lambda tokens: np.array([token2id[token] for token in tokens], dtype=np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim1 = 50\n",
    "embed_dim2 = 10\n",
    "embed_dim = embed_dim1 + embed_dim2\n",
    "embedding_matrix = np.ndarray((len(token2id), embed_dim))\n",
    "\n",
    "for idx, token in enumerate(id2token):\n",
    "    if token == '<NIL>':\n",
    "        embedding_matrix[idx, :50] = 0\n",
    "    elif token == '<NUM>':\n",
    "        embedding_matrix[idx, :50] = glove['num']\n",
    "    elif token == '<UNK>':\n",
    "        embedding_matrix[idx, :50] = glove['unk']\n",
    "    else:\n",
    "        embedding_matrix[idx, :50] = glove[token.lower()]\n",
    "    embedding_matrix[idx, 50:] = np.random.rand(embed_dim2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split and make datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = np.arange(len(df))\n",
    "np.random.shuffle(shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.ndarray((len(df), 300), dtype=np.int)[shuffle]\n",
    "labels = np.ndarray(len(df),dtype=np.long)[shuffle]\n",
    "\n",
    "for i, (feature, label) in enumerate(zip(df['token_ids'], df['Action'])):\n",
    "    features[i] = feature\n",
    "    labels[i] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.c_[features, labels]\n",
    "np.savetxt(\"data.npy\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"embedding.npy\", embedding_matrix)\n",
    "with open(\"freeze_id\", \"w\") as fp:\n",
    "    fp.write(str(token2id['<NIL>']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
